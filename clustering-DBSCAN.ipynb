{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Unlabeled Data â€“ Clustering Analysis\n",
    "### Use __DBSCAN__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Overview\n",
    " using an _artificial_ data set  \n",
    "1. load the data  \n",
    "2. check the shape and plot the content  \n",
    "3. observe the plot and decide which are the most interesting columns, to use in the plots of the clusters  \n",
    "    - make a 2d plot of the two most promising columns  \n",
    "    - exclude from the dataset the columns which seem to be only noise</br>\n",
    "4. initialize and `fit_predict` an estimator for `DBSCAN`, using the default parameters, then print the results</br>\n",
    "    - print the estimator to check the parameter values  \n",
    "    - the labels are the unique values of the predicted values  \n",
    "    - print if there is noise  \n",
    "        - if there is noise the first cluster label will be `-1`  \n",
    "    - print the number of clusters (noise excluded)  \n",
    "        - the other clusters are labeled starting from `0`  \n",
    "    - for each cluster (noise excluded) compute the __centroid__  \n",
    "        - plot the data with the centroids and the colors representing clusters  \n",
    "        - use the `plot_clusters` function provided  \n",
    "5. find the best parameters using `ParameterGrid`\n",
    "    - prepare a dictionary with the parameters lists  \n",
    "        - generate the list of the parameter combinations with `ParameterGrid`\n",
    "    - for each combination of parameters  \n",
    "        - initialize the DBSCAN estimator  \n",
    "        - `fit_predict`  \n",
    "        - extract the labels and the number of clusters excluding the _noise_  \n",
    "        - compute the silhouette score and the number of unclustered objects (noise)  \n",
    "        - filter and print the parameters and the results  \n",
    "            - print if the silhouette score is above a threshold and the percentage of unclustered is below a threshold  \n",
    "6. observe visually the most promising combination of parameters  \n",
    "    - fit and predict the estimator  \n",
    "    - plot the clusters  \n",
    "    - compute the silouette scores for the individual samples using the function `silhouette_samples`\n",
    "    - plot the silhouette scores for each sample using the function `plot_silhouette`  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "rnd_state = 42 # This variable will be used in all the procedure calls allowing a random_state parameter\n",
    "               # in this way the running can be perfectly reproduced\n",
    "               # just change this value for a different experiment\n",
    "\n",
    "# the .py files with the functions provided must be in the same directory of the .ipynb file\n",
    "   # python script provided separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "\n",
    "def plot_clusters(X, y, dim, points,\n",
    "                  labels_prefix = 'cluster', \n",
    "                  points_name = 'centroids',\n",
    "                  colors = cm.tab10, # a qualitative map           \n",
    "                  points_color = cm.tab10(10) # by default the last of the map (to be improved)\n",
    "                 ):\n",
    "    \"\"\"\n",
    "    Plot a two dimensional projection of an array of labelled points\n",
    "    X:      array with at least two columns\n",
    "    y:      vector of labels, length as number of rows in X\n",
    "    dim:    the two columns to project, inside range of X columns, e.g. (0,1)\n",
    "    points: additional points to plot as 'stars'\n",
    "    labels_prefix: prefix to the labels for the legend ['cluster']\n",
    "    points_name:   legend name for the additional points ['centroids']\n",
    "    colors: a color map\n",
    "    points_color: the color for the points\n",
    "    \"\"\"\n",
    "    # plot the labelled (colored) dataset and the points\n",
    "    labels = np.unique(y)\n",
    "    for i in range(len(labels)):\n",
    "        color = colors(i / len(labels)) # choose a color from the map\n",
    "        plt.scatter(X[y==labels[i],dim[0]], \n",
    "                    X[y==labels[i],dim[1]], \n",
    "                    s=10, \n",
    "                    c = [color], # scatter requires a sequence of colors\n",
    "                    marker='s', \n",
    "                    label=labels_prefix+str(labels[i]))\n",
    "    plt.scatter(points[:,dim[0]], \n",
    "                points[:,dim[1]], \n",
    "                s=50, \n",
    "                marker='*', \n",
    "                c=[points_color], \n",
    "                label=points_name)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
